{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:16.600602Z","iopub.status.busy":"2024-05-06T09:46:16.600152Z","iopub.status.idle":"2024-05-06T09:46:19.88448Z","shell.execute_reply":"2024-05-06T09:46:19.883447Z","shell.execute_reply.started":"2024-05-06T09:46:16.60056Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","import torchvision\n","from torchvision import transforms\n","from tqdm.auto import tqdm\n","from torch import optim\n","import time\n","import os\n","import shutil"]},{"cell_type":"markdown","metadata":{},"source":["## Overview\n","This notebook contains the implementation of original VGG16 from scratch and then retrained on cifar-10 dataset for few epochs and thereafter inferencing of model."]},{"cell_type":"markdown","metadata":{},"source":["## Defining the Network Parameters "]},{"cell_type":"markdown","metadata":{},"source":["![vgg](https://www.researchgate.net/publication/327070011/figure/fig1/AS:660549306159105@1534498635256/VGG-16-neural-network-architecture.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:19.888371Z","iopub.status.busy":"2024-05-06T09:46:19.88719Z","iopub.status.idle":"2024-05-06T09:46:19.893941Z","shell.execute_reply":"2024-05-06T09:46:19.892997Z","shell.execute_reply.started":"2024-05-06T09:46:19.888331Z"},"trusted":true},"outputs":[],"source":["KERNEL = 3\n","STRIDE = 2\n","CHANNEL = [3,64, 64, 128, 128, 256, 256, 512, 512, 512, 512, 512, 512]\n","FC = [512*7*7, 4096, 4096 ]\n","POOL_POS = [2,4,6,9,12]  #after 2nd layer..."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-05-05T09:31:59.814278Z","iopub.status.busy":"2024-05-05T09:31:59.813847Z","iopub.status.idle":"2024-05-05T09:31:59.819215Z","shell.execute_reply":"2024-05-05T09:31:59.817887Z","shell.execute_reply.started":"2024-05-05T09:31:59.814246Z"}},"source":["## Building the Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class my_relu(nn.Module):\n","    def __init(self):\n","        super().__init__()\n","    \n","    def forward(x):\n","        return max(x,0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:19.895388Z","iopub.status.busy":"2024-05-06T09:46:19.895117Z","iopub.status.idle":"2024-05-06T09:46:19.911425Z","shell.execute_reply":"2024-05-06T09:46:19.910503Z","shell.execute_reply.started":"2024-05-06T09:46:19.895363Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","KERNEL = 3\n","STRIDE = 2\n","CHANNEL = [3, 64, 64, 128, 128, 256, 256, 512, 512, 512, 512, 512, 512]\n","FC = [512*7*7, 4096, 4096]\n","POOL_POS = [2, 4, 6, 9, 12]  # after 2nd layer...\n","\n","class custom_VGG16(nn.Module):\n","    \n","    def __init__(self, num_of_classes, CHANNEL=CHANNEL, FC=FC, KERNEL=KERNEL, STRIDE=STRIDE, POOL_POS=POOL_POS):\n","        super().__init__()\n","        \n","        self.layers = nn.ModuleList()\n","        self.fc = nn.ModuleList()\n","        self.flatten = nn.Flatten()\n","        self.classifier = nn.Linear(4096, num_of_classes)\n","        \n","        for i in range(1, len(CHANNEL)):\n","            # conv 2d layers\n","            self.layers.append(nn.Conv2d(in_channels=CHANNEL[i-1], out_channels=CHANNEL[i], kernel_size=KERNEL, padding='same'))\n","            \n","            # activation layer\n","            self.layers.append(my_relu())\n","            \n","            # Max pool\n","            if i in POOL_POS:\n","                self.layers.append(nn.MaxPool2d(kernel_size=2, stride=STRIDE))\n","                \n","        # Fully connected Layers              \n","        for i in range(len(FC)-1):\n","            self.fc.append(nn.Linear(FC[i], FC[i+1]))\n","            self.fc.append(my_relu())\n","            \n","    \n","    def forward(self, x):\n","        for layer in self.layers:\n","            x = layer(x)\n","        \n","        x = self.flatten(x)\n","    \n","        for layer in self.fc:\n","            x = layer(x)\n","        \n","        # classifier \n","        x = self.classifier(x)\n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["## Weight Initialization \n","1. Intialize randomly from some distribution.\n","2. Xavier or Kaiming initialization methods.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:19.912814Z","iopub.status.busy":"2024-05-06T09:46:19.912525Z","iopub.status.idle":"2024-05-06T09:46:22.2554Z","shell.execute_reply":"2024-05-06T09:46:22.254515Z","shell.execute_reply.started":"2024-05-06T09:46:19.912789Z"},"trusted":true},"outputs":[],"source":["model = VGG16(num_of_classes = 10)\n","\n","def initialize(m):\n","    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n","        with torch.no_grad():\n","            nn.init.kaiming_uniform_(m.weight)\n","            nn.init.zeros_(m.bias)\n","\n","model = model.apply(initialize)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:22.259529Z","iopub.status.busy":"2024-05-06T09:46:22.258712Z","iopub.status.idle":"2024-05-06T09:46:35.249062Z","shell.execute_reply":"2024-05-06T09:46:35.247895Z","shell.execute_reply.started":"2024-05-06T09:46:22.259488Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print('Using: ', device)\n","from torchsummary import summary\n","summary(model.to(device), (3,224,224))"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Preperation"]},{"cell_type":"markdown","metadata":{},"source":["I will be using CIFAR10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:28:52.552544Z","iopub.status.busy":"2024-05-06T10:28:52.551749Z","iopub.status.idle":"2024-05-06T10:28:52.558824Z","shell.execute_reply":"2024-05-06T10:28:52.557848Z","shell.execute_reply.started":"2024-05-06T10:28:52.552509Z"},"trusted":true},"outputs":[],"source":["data_transforms = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","])\n","\n","class_names = {\n","    0: 'airplane',\n","    1: 'automobile',\n","    2: 'bird',\n","    3: 'cat',\n","    4: 'deer',\n","    5: 'dog',\n","    6: 'frog',\n","    7: 'horse',\n","    8: 'ship',\n","    9: 'truck'\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:35.26146Z","iopub.status.busy":"2024-05-06T09:46:35.261106Z","iopub.status.idle":"2024-05-06T09:46:36.986819Z","shell.execute_reply":"2024-05-06T09:46:36.985856Z","shell.execute_reply.started":"2024-05-06T09:46:35.261426Z"},"trusted":true},"outputs":[],"source":["train_set = torchvision.datasets.CIFAR10(root = '/', download = True, \n","                                          train = True, transform = data_transforms)\n","\n","\n","test_set =  torchvision.datasets.CIFAR10(root = '/', download = True, \n","                                          train = False, transform = data_transforms)\n","\n","train_set = torch.utils.data.Subset(train_set, range(5000))\n","test_set = torch.utils.data.Subset(train_set, range(1000)) \n","\n","print('The size of dataset is :', len(train_set), len(test_set))\n","\n","\n","train_loader =  torch.utils.data.DataLoader(train_set, batch_size = 32,  shuffle = True)\n","test_loader = torch.utils.data.DataLoader(test_set, shuffle = False, batch_size = 32)\n","\n","#Making things easy, so storing it in a dictionary \n","dataloader = {\n","    'train': train_loader,\n","    'val': test_loader\n","}\n","\n","dataset_sizes = {\n","    \"train\": len(train_set),\n","    \"val\": len(test_set)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## Training the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:36.988594Z","iopub.status.busy":"2024-05-06T09:46:36.988222Z","iopub.status.idle":"2024-05-06T09:46:37.003912Z","shell.execute_reply":"2024-05-06T09:46:37.002932Z","shell.execute_reply.started":"2024-05-06T09:46:36.988559Z"},"trusted":true},"outputs":[],"source":["def train(model, optimizer, scheduler , criterion, num_of_epochs = 20, dataloader = dataloader):\n","    since = time.time()\n","\n","    #storing epoch data\n","    epoch_data =     {\n","        'epoch': [],\n","        'train': {'loss': [], 'acc': []},\n","        'val': {'loss': [], 'acc': [] }\n","    }\n","    \n","    \n","    # Create a temporary directory in Kaggle's temp directory\n","    tempdir = '/kaggle/working/temp'\n","    os.makedirs(tempdir, exist_ok=True)\n","    best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n","\n","    torch.save(model.state_dict(), best_model_params_path)\n","    best_acc = 0.0\n","\n","    for epoch in range(num_of_epochs):\n","        print(f'Epoch {epoch+1}/{num_of_epochs}')\n","        print('-' * 10)\n","        epoch_data['epoch'].append(epoch+1)\n","        \n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","            \n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            \n","\n","            for inputs, labels in tqdm(dataloader[phase], leave=False):\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)   #normalize for batch(applicable if different batch sizes)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","            epoch_data[phase]['loss'].append(epoch_loss)\n","            epoch_data[phase]['acc'].append(epoch_acc)\n","\n","            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                torch.save(model.state_dict(), best_model_params_path)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n","    print(f'Best val Acc: {best_acc:4f}')\n","\n","    model.load_state_dict(torch.load(best_model_params_path))\n","\n","    # Clean up the temporary directory\n","    shutil.rmtree(tempdir)\n","\n","    return model, epoch_data\n","                "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:37.005996Z","iopub.status.busy":"2024-05-06T09:46:37.005568Z","iopub.status.idle":"2024-05-06T09:46:37.018786Z","shell.execute_reply":"2024-05-06T09:46:37.017943Z","shell.execute_reply.started":"2024-05-06T09:46:37.005962Z"},"trusted":true},"outputs":[],"source":["model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer_ft = optim.Adam(model.parameters(), lr= 0.001)\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T09:46:37.020205Z","iopub.status.busy":"2024-05-06T09:46:37.019864Z","iopub.status.idle":"2024-05-06T10:06:14.583041Z","shell.execute_reply":"2024-05-06T10:06:14.582132Z","shell.execute_reply.started":"2024-05-06T09:46:37.020171Z"},"trusted":true},"outputs":[],"source":["model, epoch_data = train(model, optimizer_ft, exp_lr_scheduler, criterion, num_of_epochs = 15)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:06:14.584492Z","iopub.status.busy":"2024-05-06T10:06:14.584197Z","iopub.status.idle":"2024-05-06T10:06:15.911665Z","shell.execute_reply":"2024-05-06T10:06:15.910418Z","shell.execute_reply.started":"2024-05-06T10:06:14.584466Z"},"trusted":true},"outputs":[],"source":["torch.save(model, 'model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["## Transferring weights:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:06:15.913254Z","iopub.status.busy":"2024-05-06T10:06:15.912933Z","iopub.status.idle":"2024-05-06T10:06:15.917623Z","shell.execute_reply":"2024-05-06T10:06:15.916593Z","shell.execute_reply.started":"2024-05-06T10:06:15.913224Z"},"trusted":true},"outputs":[],"source":["# vggmodel = torchvision.models.vgg16(weights = True)\n","# conv_wts = vggmodel.features.state_dict()\n","\n","# for i in range(len(model.layers)):\n","#   if type(model.layers[i]) == nn.Conv2d and type( type(vggmodel.features[i]))==nn.Conv2d:\n","#     with torch.no_grad():\n","#       model.layers[i].weight = vggmodel.features[i].weight\n","#       model.layers[i].bias = vggmodel.features[i].bias\n","\n","\n","# print('Weights Copied')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:27:29.152838Z","iopub.status.busy":"2024-05-06T10:27:29.152448Z","iopub.status.idle":"2024-05-06T10:27:31.599237Z","shell.execute_reply":"2024-05-06T10:27:31.597607Z","shell.execute_reply.started":"2024-05-06T10:27:29.152802Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","import requests\n","img = Image.open(requests.get('https://images.pexels.com/photos/46148/aircraft-jet-landing-cloud-46148.jpeg', stream= True).raw)\n","img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:27:31.602094Z","iopub.status.busy":"2024-05-06T10:27:31.601634Z","iopub.status.idle":"2024-05-06T10:27:31.638211Z","shell.execute_reply":"2024-05-06T10:27:31.637309Z","shell.execute_reply.started":"2024-05-06T10:27:31.602049Z"},"trusted":true},"outputs":[],"source":["img = data_transforms(img)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-06T10:29:16.72019Z","iopub.status.busy":"2024-05-06T10:29:16.719232Z","iopub.status.idle":"2024-05-06T10:29:16.738039Z","shell.execute_reply":"2024-05-06T10:29:16.736963Z","shell.execute_reply.started":"2024-05-06T10:29:16.720152Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Therby the VGG16 was implemented from scratch and was trained on Cifar10 dataset."]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
